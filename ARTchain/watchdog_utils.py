import os
import shutil
import hashlib
import json
from datetime import datetime
import zipfile

def hash_file(file_path):
    with open(file_path, "rb") as f:
        return hashlib.sha256(f.read()).hexdigest()

def add_to_watchlist(watchdog, file_path, origin="user"):
    rel_path = os.path.relpath(file_path, watchdog.root_dir).replace("\\", "/")
    if (
        not any(f["path"] == rel_path for f in watchdog.watchlist) and
        "ARTchain/backups" not in rel_path
    ):
        abs_dir = os.path.dirname(os.path.join(watchdog.root_dir, rel_path))
        os.makedirs(abs_dir, exist_ok=True)
        watchdog.watchlist.append({
            "path": rel_path,
            "origin": origin,
            "added": datetime.now().isoformat()
        })
        watchdog.save_watchlist()
        print(f"Added {rel_path} to watchlist as {origin} (folder created if missing)")

def scan_and_update_watchlist(watchdog):
    existing_paths = {f["path"] for f in watchdog.watchlist}
    for root, _, files in os.walk(watchdog.root_dir):
        if "ARTchain/backups" in root.replace("\\", "/"):
            continue
        for file in files:
            if file.endswith(".py"):
                rel_path = os.path.relpath(os.path.join(root, file), watchdog.root_dir).replace("\\", "/")
                if (
                    rel_path not in existing_paths and
                    "__pycache__" not in rel_path and
                    not rel_path.endswith(".pyc") and
                    "venv" not in rel_path
                ):
                    add_to_watchlist(watchdog, os.path.join(watchdog.root_dir, rel_path))

def backup(watchdog):
    scan_and_update_watchlist(watchdog)
    summary = {"files": [], "timestamp": datetime.now().isoformat()}
    zip_path = os.path.join(watchdog.backup_dir, "backups.zip")
    temp_dir = os.path.join(watchdog.backup_dir, "temp")
    os.makedirs(temp_dir, exist_ok=True)

    zip_password = os.getenv("WATCHDOG_ZIP_PASSWORD", "yarr").encode()

    # Only back up files that still exist
    for file_info in watchdog.watchlist:
        rel_path = file_info["path"].replace("\\", "/")
        src_path = os.path.join(watchdog.root_dir, rel_path)
        if os.path.exists(src_path) and src_path.endswith(".py"):
            file_hash = hash_file(src_path)
            with open(src_path, "r", encoding="utf-8") as src_file:
                content = src_file.read()
            backup_header = f"# BACKUP FILE - DO NOT EDIT - Generated by ART Watchdog on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            temp_path = os.path.join(temp_dir, rel_path)
            os.makedirs(os.path.dirname(temp_path), exist_ok=True)
            with open(temp_path, "w", encoding="utf-8") as temp_file:
                temp_file.write(backup_header + content)
            summary["files"].append({
                "original_path": rel_path,
                "hash": file_hash,
                "backed_up": datetime.now().isoformat()
            })

    # Rewrite zip with only current files—prunes obsolete ones
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.setpassword(zip_password)
        for file_info in summary["files"]:
            rel_path = file_info["original_path"]
            temp_path = os.path.join(temp_dir, rel_path)
            zf.write(temp_path, rel_path, compress_type=zipfile.ZIP_DEFLATED)
            zf.getinfo(rel_path).comment = file_info["hash"].encode()

    shutil.rmtree(temp_dir, ignore_errors=True)

    summary_path = os.path.join(watchdog.backup_dir, "backup_summary.json")
    with open(summary_path, "w") as f:
        json.dump(summary, f, indent=4)
    print("Watchdog Backup Report:")
    print(f"Backed up {len(summary['files'])} files to {zip_path}")
    for file in summary["files"]:
        print(f"- {file['original_path']} (Hash: {file['hash'][:8]}...)")

def rollback(watchdog, specific_file=None):
    zip_path = os.path.join(watchdog.backup_dir, "backups.zip")
    if not os.path.exists(zip_path):
        print("Watchdog: No backups found, ye scurvy dog!")
        return

    zip_password = os.getenv("WATCHDOG_ZIP_PASSWORD", "yarr").encode()
    restored = []
    temp_dir = os.path.join(watchdog.backup_dir, "temp_rollback")
    os.makedirs(temp_dir, exist_ok=True)

    with zipfile.ZipFile(zip_path, "r", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.setpassword(zip_password)
        for file_info in zf.infolist():
            rel_path = file_info.filename.replace("\\", "/")
            if specific_file and rel_path != specific_file.replace("\\", "/"):
                continue
            zf.extract(file_info, temp_dir)
            src_path = os.path.join(temp_dir, rel_path)
            dst_path = os.path.join(watchdog.root_dir, rel_path)
            os.makedirs(os.path.dirname(dst_path), exist_ok=True)
            with open(src_path, "r", encoding="utf-8") as src_file:
                content = src_file.read().split("\n", 1)[1]  # Skip header
            with open(dst_path, "w", encoding="utf-8") as dst_file:
                dst_file.write(content)
            restored.append(rel_path)

    shutil.rmtree(temp_dir, ignore_errors=True)

    print("Watchdog Rollback Report:")
    if restored:
        print(f"Restored {len(restored)} files:")
        for path in restored:
            print(f"- {path}")
    else:
        print("Nothin’ restored—check yer backups!")